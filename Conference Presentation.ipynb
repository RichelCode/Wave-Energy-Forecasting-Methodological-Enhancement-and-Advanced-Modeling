{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0433a37-9c12-45b5-b7ec-496695dfbedd",
   "metadata": {},
   "source": [
    "## WAVE ENERGY FORECASTING: A RIGOROUS MACHINE LEARNING APPROACH\n",
    "\n",
    "Project: Advanced Wave Energy Flux Forecasting Using Ensemble Methods and \n",
    "         Deep Learning with Uncertainty Quantification\n",
    "Target Station: NDBC Buoy 41025 (Diamond Shoals, NC)\n",
    "\n",
    "Repository: https://github.com/RichelCode/Wave-Energy-Forecasting-Methodological-Enhancement-and-Advanced-Modeling\n",
    "\n",
    "Paper Reference: Building upon \"A Hybrid Machine Learning Approach to Wave \n",
    "                 Energy Forecasting\" (TIefu et al., 2021, NAPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ca481-95e0-4b83-a2e8-ccdb9268a38c",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "This notebook implements a comprehensive wave energy forecasting system that addresses critical methodological limitations in existing literature while advancing toward state-of-the-art performance. Our work builds upon and significantly improves the methodology presented in TIefu et al. (2021), incorporating:\n",
    "\n",
    "Key Improvements:\n",
    "- Rigorous time series cross-validation (eliminating data leakage)\n",
    "- Spatial imputation using neighbor station data (preserving temporal continuity)\n",
    "- Comprehensive feature engineering with temporal lags and domain knowledge\n",
    "- Systematic hyperparameter optimization using Bayesian methods\n",
    "- Statistical significance testing for model comparisons\n",
    "- Neural network baselines (LSTM, GRU) alongside tree-based methods\n",
    "- Probabilistic forecasting with uncertainty quantification\n",
    "- Multi-horizon evaluation (1h, 3h, 6h, 12h, 24h ahead)\n",
    "\n",
    "## Problem Context and Motivation\n",
    "\n",
    "###  The Wave Energy Challenge\n",
    "\n",
    "Wave energy represents a **largely untapped renewable resource** with estimated potential of:\n",
    "- **1,170 TWh/year** along US coastlines (EPRI, 2011)\n",
    "- **2-3 TW global theoretical capacity** (Gunn & Stock-Williams, 2012)\n",
    "- **Predictable and high energy density** compared to wind/solar\n",
    "\n",
    "However, **grid integration of wave energy** requires accurate forecasting for:\n",
    "\n",
    "1. **Power System Operations:**\n",
    "   - Unit commitment and economic dispatch optimization\n",
    "   - Spinning reserve allocation\n",
    "   - Transmission congestion management\n",
    "   - Ancillary service procurement\n",
    "\n",
    "2. **Wave Energy Converter (WEC) Management:**\n",
    "   - Preventive maintenance scheduling during calm periods\n",
    "   - Survival mode activation before extreme events\n",
    "   - Optimal power extraction strategies\n",
    "   - Component lifetime optimization\n",
    "\n",
    "3. **Market Participation:**\n",
    "   - Day-ahead and real-time market bidding\n",
    "   - Financial risk management\n",
    "   - Revenue optimization under uncertainty\n",
    "\n",
    "### Critical Forecasting Parameters\n",
    "\n",
    "Wave energy flux (kW/m) depends primarily on:\n",
    "\n",
    "**Significant Wave Height (H_s):** \n",
    "- The mean height of the highest 1/3 of waves in a time period\n",
    "- Directly measured by buoy accelerometers\n",
    "- Energy ∝ H_s² (quadratic relationship amplifies forecast errors)\n",
    "\n",
    "**Wave Period (T):**\n",
    "- Dominant Period (DPD): Period of peak energy in wave spectrum\n",
    "- Average Period (APD): Mean period of all waves\n",
    "- Energy ∝ T (linear relationship but crucial for power capture)\n",
    "\n",
    "**Wave Energy Flux Formula:**\n",
    "$$E = \\frac{\\rho g^2 H_s^2 T}{64\\pi} \\approx 0.49 H_s^2 T \\text{ (kW/m in deep water)}$$\n",
    "\n",
    "Where:\n",
    "- ρ = seawater density ≈ 1025 kg/m³\n",
    "- g = gravitational acceleration = 9.81 m/s²\n",
    "- H_s = significant wave height (m)\n",
    "- T = wave period (s)\n",
    "\n",
    "**Implication:** A 10% error in H_s translates to ~20% error in energy flux due to quadratic relationship. This demands high-accuracy forecasting.\n",
    "\n",
    "\n",
    "## Literature Review and Research Gaps\n",
    "\n",
    "### Existing Approaches\n",
    "\n",
    "**Physics-Based Models:**\n",
    "- WAVEWATCH III, SWAN (Simulating WAves Nearshore)\n",
    "- **Pros:** Based on first principles, global applicability\n",
    "- **Cons:** Computationally expensive (hours for 24h forecast), require accurate wind forcing, cumulative error from physics approximations\n",
    "\n",
    "**Statistical/ML Models:**\n",
    "- ARIMA, SARIMA for time series\n",
    "- Neural Networks (ANN, LSTM, GRU)\n",
    "- Tree-based methods (Random Forest, XGBoost)\n",
    "- **Pros:** Fast inference, learn from data patterns\n",
    "- **Cons:** Site-specific training, require substantial historical data\n",
    "\n",
    "**Hybrid Models:**\n",
    "- Decomposition + ML (VMD-LSTM, EMD-XGBoost)\n",
    "- Stacking ensembles combining multiple algorithms\n",
    "- Physics-informed neural networks\n",
    "- **Pros:** Leverage complementary strengths\n",
    "- **Cons:** Increased complexity, hyperparameter tuning challenges\n",
    "\n",
    "### Identified Research Gaps (TIefu et al., 2021)\n",
    "\n",
    "After thorough review of the foundational paper, we identified **critical methodological deficiencies:**\n",
    "\n",
    "| Issue | Impact | Our Solution |\n",
    "|-------|--------|--------------|\n",
    "| Single train-test split | Overfitting risk, no robustness assessment | Time series cross-validation |\n",
    "| No hyperparameter tuning | Unfair model comparison | Bayesian optimization (Optuna) |\n",
    "| Missing neural network baselines | Incomplete various model comparison | LSTM, GRU, TCN (Temporal Convolutional Neural Network) implementations |\n",
    "| Simple outlier deletion | Data loss, temporal gaps | Spatial imputation from neighbor station |\n",
    "| No temporal lags | Limited forecasting capability | Lag features [1, 3, 6, 12, 24, 48h] |\n",
    "| No statistical testing | Uncertain significance of improvements | Paired t-tests, DM tests, bootstrap CI |\n",
    "| Point predictions only | No uncertainty quantification | Quantile regression, conformal prediction |\n",
    "| Single horizon evaluation | Limited operational utility | Multi-horizon [1, 3, 6, 12, 24h] |\n",
    "\n",
    "**Our work systematically addresses each of these gaps.**\n",
    "\n",
    "\n",
    "## Research Objectives and Hypotheses\n",
    "\n",
    "### Primary Objectives\n",
    "\n",
    "**Objective 1:** Develop a methodologically rigorous wave energy forecasting framework that eliminates common pitfalls in applied ML research (data leakage, inadequate validation, missing baselines).\n",
    "\n",
    "**Objective 2:** Systematically compare tree-based ensemble methods (XGBoost, Random Forest) and deep learning architectures (LSTM, GRU, TCN) under fair experimental conditions with proper hyperparameter tuning.\n",
    "\n",
    "**Objective 3:** Design and validate a heterogeneous ensemble approach that combines complementary model strengths while avoiding redundancy.\n",
    "\n",
    "**Objective 4:** Implement probabilistic forecasting to quantify prediction uncertainty for operational decision-making.\n",
    "\n",
    "**Objective 5:** Evaluate performance across multiple forecast horizons (1-24 hours) and wave energy regimes (low, moderate, high, extreme).\n",
    "\n",
    "\n",
    "## Data Sources and Study Site\n",
    "\n",
    "### Target Location: Diamond Shoals, NC (NDBC Station 41025)\n",
    "\n",
    "**Geographic Characteristics:**\n",
    "- **Coordinates:** 35.006°N, 75.402°W\n",
    "- **Location:** 15 nautical miles southeast of Cape Hatteras, North Carolina\n",
    "- **Water Depth:** 48.8 meters (deep water conditions)\n",
    "- **Exposure:** Open Atlantic Ocean, high wave energy environment\n",
    "- **Wave Climate:** Mixed sea and swell, strong seasonal variability\n",
    "\n",
    "**Strategic Importance:**\n",
    "- Located in the **U.S. Mid-Atlantic wave energy hotspot**\n",
    "- Representative of conditions for proposed WEC deployments\n",
    "- Long historical record (1990s-present) for robust modeling\n",
    "- Well-maintained instrument with high data quality\n",
    "\n",
    "**Why This Location?**\n",
    "- Cape Hatteras region has **average wave power >30 kW/m** (top 10% of US sites)\n",
    "- Proximity to population centers (Virginia, North Carolina coast)\n",
    "- Overlaps with proposed offshore wind farms (potential co-location)\n",
    "- Existing grid infrastructure for renewable integration\n",
    "\n",
    "### Data Description\n",
    "\n",
    "**Source:** National Data Buoy Center (NDBC), NOAA\n",
    "**Temporal Coverage:** January 2014 - December 2019 (6 years)\n",
    "**Temporal Resolution:** Hourly measurements\n",
    "**Total Potential Records:** 52,608 hours\n",
    "\n",
    "**Variables Available:**\n",
    "\n",
    "| Variable | Symbol | Unit | Description | Role in Analysis |\n",
    "|----------|--------|------|-------------|------------------|\n",
    "| Significant Wave Height | WVHT | meters | Mean height of highest 1/3 waves | **Primary Target** |\n",
    "| Dominant Wave Period | DPD | seconds | Period at spectral peak | **Primary Target** |\n",
    "| Average Wave Period | APD | seconds | Mean wave period | **Secondary Target/Feature** |\n",
    "| Mean Wave Direction | MWD | degrees | Direction waves coming from | Feature |\n",
    "| Wind Direction | WDIR | degrees | Direction wind coming from | Feature |\n",
    "| Wind Speed | WSPD | m/s | 10-minute average wind speed | Feature |\n",
    "| Wind Gust | GST | m/s | Peak 5-second wind speed | Feature |\n",
    "| Atmospheric Pressure | PRES | hPa | Sea-level pressure | Feature |\n",
    "| Air Temperature | ATMP | °C | Air temperature | Feature |\n",
    "| Sea Surface Temperature | WTMP | °C | Water temperature at 1m depth | Feature |\n",
    "\n",
    "**Derived Targets:**\n",
    "- **Wave Energy Flux** (kW/m): Calculated from WVHT and DPD using deep water approximation\n",
    "- **Wave Power Production** (kW): Theoretical power capture assuming 30% WEC efficiency\n",
    "\n",
    "### Data Quality Considerations\n",
    "\n",
    "**Known Issues (from NDBC documentation):**\n",
    "- Missing data codes: 999, 9999, 99.0 (varies by variable)\n",
    "- Sensor failures during extreme weather events (non-random missingness)\n",
    "- Occasional calibration gaps during maintenance periods\n",
    "- Wave direction uncertainty during low wave conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584925c-2b54-4a0f-ba98-a907681686e1",
   "metadata": {},
   "source": [
    "# DATA LOADING AND INITIAL ASSESSMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9687397-b580-4c6e-bdd7-c8cd66742501",
   "metadata": {},
   "source": [
    "## Understanding NDBC Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d9d26d-853d-4ec8-9970-567b0d93b427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDBC Data Format Documentation\n",
      "================================================================================\n",
      "✓ Yearly text files with space-separated values\n",
      "✓ First two rows contain headers and units\n",
      "✓ Missing data coded as 999, 9999, 99, or MM\n",
      "✓ Hourly temporal resolution (typically at :00 or :50 minutes)\n",
      "================================================================================\n",
      "NDBC Data Format Documentation\n",
      "================================================================================\n",
      "✓ Yearly text files with space-separated values\n",
      "✓ First two rows contain headers and units\n",
      "✓ Missing data coded as 999, 9999, 99, or MM\n",
      "✓ Hourly temporal resolution (typically at :00 or :50 minutes)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NDBC Standard Meteorological Data Format (from NDBC documentation):\n",
    "\n",
    "The data files contain hourly observations with the following characteristics:\n",
    "\n",
    "FILE STRUCTURE:\n",
    "- Line 1: Column headers (variable names)\n",
    "- Line 2: Unit specifications  \n",
    "- Line 3+: Hourly data records\n",
    "\n",
    "MISSING DATA CODES:\n",
    "- 999  or 999.0  → Missing wave/wind data\n",
    "- 9999 or 9999.0 → Missing pressure data  \n",
    "- 99   or 99.0   → Missing temperature data\n",
    "- MM   → Missing month/time component\n",
    "\n",
    "COMMON VARIABLES:\n",
    "#YY  = Year (2014-2019 in our case)\n",
    "MM   = Month (1-12)\n",
    "DD   = Day (1-31)\n",
    "hh   = Hour (0-23)\n",
    "mm   = Minute (usually 00 or 50)\n",
    "WDIR = Wind direction (degrees, meteorological convention)\n",
    "WSPD = Wind speed (m/s)\n",
    "GST  = Wind gust (m/s)\n",
    "WVHT = Significant wave height (meters)\n",
    "DPD  = Dominant wave period (seconds)\n",
    "APD  = Average wave period (seconds)  \n",
    "MWD  = Mean wave direction (degrees)\n",
    "PRES = Sea level pressure (hPa)\n",
    "ATMP = Air temperature (°C)\n",
    "WTMP = Sea surface temperature (°C)\n",
    "\"\"\"\n",
    "\n",
    "print(\"NDBC Data Format Documentation\")\n",
    "print(\"=\" * 80)\n",
    "print(\"✓ Yearly text files with space-separated values\")\n",
    "print(\"✓ First two rows contain headers and units\")\n",
    "print(\"✓ Missing data coded as 999, 9999, 99, or MM\")\n",
    "print(\"✓ Hourly temporal resolution (typically at :00 or :50 minutes)\")\n",
    "print(\"=\" * 80)\n",
    "\"\"\"\n",
    "NDBC Standard Meteorological Data Format (from NDBC documentation):\n",
    "\n",
    "The data files contain hourly observations with the following characteristics:\n",
    "\n",
    "FILE STRUCTURE:\n",
    "- Line 1: Column headers (variable names)\n",
    "- Line 2: Unit specifications  \n",
    "- Line 3+: Hourly data records\n",
    "\n",
    "MISSING DATA CODES:\n",
    "- 999  or 999.0  → Missing wave/wind data\n",
    "- 9999 or 9999.0 → Missing pressure data  \n",
    "- 99   or 99.0   → Missing temperature data\n",
    "- MM   → Missing month/time component\n",
    "\n",
    "COMMON VARIABLES:\n",
    "#YY  = Year (2014-2019 in our case)\n",
    "MM   = Month (1-12)\n",
    "DD   = Day (1-31)\n",
    "hh   = Hour (0-23)\n",
    "mm   = Minute (usually 00 or 50)\n",
    "WDIR = Wind direction (degrees, meteorological convention)\n",
    "WSPD = Wind speed (m/s)\n",
    "GST  = Wind gust (m/s)\n",
    "WVHT = Significant wave height (meters)\n",
    "DPD  = Dominant wave period (seconds)\n",
    "APD  = Average wave period (seconds)  \n",
    "MWD  = Mean wave direction (degrees)\n",
    "PRES = Sea level pressure (hPa)\n",
    "ATMP = Air temperature (°C)\n",
    "WTMP = Sea surface temperature (°C)\n",
    "\"\"\"\n",
    "\n",
    "print(\"NDBC Data Format Documentation\")\n",
    "print(\"=\" * 80)\n",
    "print(\"✓ Yearly text files with space-separated values\")\n",
    "print(\"✓ First two rows contain headers and units\")\n",
    "print(\"✓ Missing data coded as 999, 9999, 99, or MM\")\n",
    "print(\"✓ Hourly temporal resolution (typically at :00 or :50 minutes)\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9829054-4a25-4e5a-9e67-febff55ffcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b20caa-83e1-46fc-8c0b-13caf57680aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard NDBC missing-value codes\n",
    "na_vals = [99, 99.0, 999, 999.0, 9999, 9999.0, \"MM\"]\n",
    "\n",
    "\n",
    "def read_ndbc_stdmet(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a single NDBC standard meteorological file.\n",
    "\n",
    "    - Finds the '#YY MM DD hh mm ...' header line\n",
    "    - Uses that as column names\n",
    "    - Treats NDBC missing codes as NaN\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        header = None\n",
    "        for line in f:\n",
    "            if line.startswith(\"#YY\") or line.startswith(\"YY\"):\n",
    "                header = line.lstrip(\"#\").strip().split()\n",
    "                break\n",
    "\n",
    "    if header is None:\n",
    "        raise ValueError(f\"Couldn't find #YY header in {path}\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep=r\"\\s+\",\n",
    "        comment=\"#\",\n",
    "        header=None,\n",
    "        names=header,\n",
    "        na_values=na_vals,\n",
    "        engine=\"python\",\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184fed2f-667c-4d74-b5a1-d36e8faa8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_station_df(station_prefix: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a single DataFrame for a station from yearly NDBC files.\n",
    "\n",
    "    Example:\n",
    "      station_prefix = '41025h'  -> matches 41025h2014.txt, 41025h2015.txt, ...\n",
    "    \"\"\"\n",
    "    files = sorted(glob.glob(f\"{station_prefix}*.txt\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files found matching pattern {station_prefix}*.txt\")\n",
    "\n",
    "    print(\"Found files:\")\n",
    "    for f in files:\n",
    "        print(\"  \", os.path.basename(f))\n",
    "\n",
    "    dfs = [read_ndbc_stdmet(f) for f in files]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Standardize time columns\n",
    "    col_map = {\n",
    "        \"#YY\": \"year\",\n",
    "        \"YY\": \"year\",\n",
    "        \"MM\": \"month\",\n",
    "        \"DD\": \"day\",\n",
    "        \"hh\": \"hour\",\n",
    "        \"mm\": \"minute\",\n",
    "    }\n",
    "    df = df.rename(columns={k: v for k, v in col_map.items() if k in df.columns})\n",
    "\n",
    "    # Build datetime index\n",
    "    time_cols = [\"year\", \"month\", \"day\", \"hour\", \"minute\"]\n",
    "    df[\"datetime\"] = pd.to_datetime(df[time_cols], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"datetime\"]).set_index(\"datetime\").sort_index()\n",
    "    df = df.drop(columns=[c for c in time_cols if c in df.columns])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f2f41f-38ae-484f-9aba-738f6ace0434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n",
      "C:\\Users\\attafuro\\Desktop\\Wave Analysis\n",
      "\n",
      "Files in this directory:\n",
      "   .ipynb_checkpoints\n",
      "   41025h2014.txt\n",
      "   41025h2015.txt\n",
      "   41025h2016.txt\n",
      "   41025h2017.txt\n",
      "   41025h2018.txt\n",
      "   41025h2019.txt\n",
      "   44095h2014.txt\n",
      "   44095h2015.txt\n",
      "   44095h2016.txt\n",
      "   44095h2017.txt\n",
      "   44095h2018.txt\n",
      "   44095h2019.txt\n",
      "   APD_LSTM_predictions.xlsx\n",
      "   APD_predictions.xlsx\n",
      "   APD_results.xlsx\n",
      "   Conference Presentation.ipynb\n",
      "   Imputing Neighbor Stations .ipynb\n",
      "   Imputing with Neighbor Stations.ipynb\n",
      "   Imputing with traditional method.ipynb\n",
      "   WVHT_LSTM_predictions.xlsx\n",
      "   WVHT_T_Predictions_with_Neighbor.xlsx\n",
      "   WVHT_predictions.xlsx\n",
      "   Wave Analysis.ipynb\n",
      "   Wave_Energy_Flux.xlsx\n",
      "   Wave_Energy_Flux_Metrics.xlsx\n",
      "   Wave_Energy_Flux_TimeSeries.xlsx\n",
      "   Wave_analysis_Considering_Two_Stations.ipynb\n",
      "\n",
      "Searching for files with pattern: 41025h*.txt\n",
      "Found 6 file(s):\n",
      "  • 41025h2014.txt        (  597.5 KB)\n",
      "  • 41025h2015.txt        (  616.6 KB)\n",
      "  • 41025h2016.txt        (  755.9 KB)\n",
      "  • 41025h2017.txt        ( 1306.5 KB)\n",
      "  • 41025h2018.txt        ( 4376.7 KB)\n",
      "  • 41025h2019.txt        ( 2679.5 KB)\n",
      "Found files:\n",
      "   41025h2014.txt\n",
      "   41025h2015.txt\n",
      "   41025h2016.txt\n",
      "   41025h2017.txt\n",
      "   41025h2018.txt\n",
      "   41025h2019.txt\n",
      "\n",
      "Combined Station 41025 DataFrame:\n",
      "------------------------------------------------------------\n",
      "Index range: 2013-12-31 23:50:00 → 2019-12-31 23:50:00\n",
      "Total rows: 117882\n",
      "Columns: ['WDIR', 'WSPD', 'GST', 'WVHT', 'DPD', 'APD', 'MWD', 'PRES', 'ATMP', 'WTMP', 'DEWP', 'VIS', 'TIDE']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WDIR</th>\n",
       "      <th>WSPD</th>\n",
       "      <th>GST</th>\n",
       "      <th>WVHT</th>\n",
       "      <th>DPD</th>\n",
       "      <th>APD</th>\n",
       "      <th>MWD</th>\n",
       "      <th>PRES</th>\n",
       "      <th>ATMP</th>\n",
       "      <th>WTMP</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>VIS</th>\n",
       "      <th>TIDE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-31 23:50:00</th>\n",
       "      <td>305.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.56</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1025.5</td>\n",
       "      <td>11.8</td>\n",
       "      <td>23.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 00:50:00</th>\n",
       "      <td>301.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6.25</td>\n",
       "      <td>4.40</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1026.6</td>\n",
       "      <td>11.8</td>\n",
       "      <td>23.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:50:00</th>\n",
       "      <td>305.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.89</td>\n",
       "      <td>5.88</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1027.6</td>\n",
       "      <td>11.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:50:00</th>\n",
       "      <td>308.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.89</td>\n",
       "      <td>5.88</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1027.9</td>\n",
       "      <td>11.7</td>\n",
       "      <td>23.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:50:00</th>\n",
       "      <td>322.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>6.25</td>\n",
       "      <td>4.38</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1027.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      WDIR  WSPD   GST  WVHT   DPD   APD    MWD    PRES  ATMP  \\\n",
       "datetime                                                                        \n",
       "2013-12-31 23:50:00  305.0   7.0  10.0  0.96  5.56  4.41    2.0  1025.5  11.8   \n",
       "2014-01-01 00:50:00  301.0   6.8   9.5  0.96  6.25  4.40  360.0  1026.6  11.8   \n",
       "2014-01-01 01:50:00  305.0   7.5   9.5  0.89  5.88  4.23    2.0  1027.6  11.9   \n",
       "2014-01-01 02:50:00  308.0   6.6   9.4  0.89  5.88  4.15    3.0  1027.9  11.7   \n",
       "2014-01-01 03:50:00  322.0   7.0  10.1  0.92  6.25  4.38   26.0  1027.9  12.0   \n",
       "\n",
       "                     WTMP  DEWP  VIS  TIDE  \n",
       "datetime                                    \n",
       "2013-12-31 23:50:00  23.3   1.8  NaN   NaN  \n",
       "2014-01-01 00:50:00  23.3   1.4  NaN   NaN  \n",
       "2014-01-01 01:50:00  23.3   0.5  NaN   NaN  \n",
       "2014-01-01 02:50:00  23.3  -0.1  NaN   NaN  \n",
       "2014-01-01 03:50:00  23.2  -0.3  NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WDIR</th>\n",
       "      <th>WSPD</th>\n",
       "      <th>GST</th>\n",
       "      <th>WVHT</th>\n",
       "      <th>DPD</th>\n",
       "      <th>APD</th>\n",
       "      <th>MWD</th>\n",
       "      <th>PRES</th>\n",
       "      <th>ATMP</th>\n",
       "      <th>WTMP</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>VIS</th>\n",
       "      <th>TIDE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:10:00</th>\n",
       "      <td>266.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008.9</td>\n",
       "      <td>15.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:20:00</th>\n",
       "      <td>263.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:30:00</th>\n",
       "      <td>271.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>11.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>22.9</td>\n",
       "      <td>7.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:40:00</th>\n",
       "      <td>277.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>10.81</td>\n",
       "      <td>5.44</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1009.1</td>\n",
       "      <td>15.7</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:50:00</th>\n",
       "      <td>275.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      WDIR  WSPD   GST  WVHT    DPD   APD   MWD    PRES  ATMP  \\\n",
       "datetime                                                                        \n",
       "2019-12-31 23:10:00  266.0   8.3  10.7   NaN    NaN   NaN   NaN  1008.9  15.5   \n",
       "2019-12-31 23:20:00  263.0   8.9  11.2   NaN    NaN   NaN   NaN  1009.0  15.5   \n",
       "2019-12-31 23:30:00  271.0   8.6  11.5   NaN    NaN   NaN   NaN  1009.2  15.7   \n",
       "2019-12-31 23:40:00  277.0   8.8  12.1  1.25  10.81  5.44  20.0  1009.1  15.7   \n",
       "2019-12-31 23:50:00  275.0   9.4  12.6   NaN    NaN   NaN   NaN  1009.2  15.7   \n",
       "\n",
       "                     WTMP  DEWP  VIS  TIDE  \n",
       "datetime                                    \n",
       "2019-12-31 23:10:00  23.1   7.0  NaN   NaN  \n",
       "2019-12-31 23:20:00  23.1   7.0  NaN   NaN  \n",
       "2019-12-31 23:30:00  22.9   7.6  NaN   NaN  \n",
       "2019-12-31 23:40:00  23.0   6.6  NaN   NaN  \n",
       "2019-12-31 23:50:00  23.0   6.3  NaN   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Current working directory:\")\n",
    "print(os.getcwd())\n",
    "print(\"\\nFiles in this directory:\")\n",
    "for f in sorted(os.listdir()):\n",
    "    print(\"  \", f)\n",
    "\n",
    "# Pattern for your files: 41025h2014.txt, 41025h2015.txt, ...\n",
    "file_pattern = \"41025h*.txt\"\n",
    "\n",
    "data_files = sorted(glob.glob(file_pattern))\n",
    "\n",
    "print(\"\\nSearching for files with pattern:\", file_pattern)\n",
    "print(f\"Found {len(data_files)} file(s):\")\n",
    "for f in data_files:\n",
    "    size_kb = os.path.getsize(f) / 1024\n",
    "    print(f\"  • {os.path.basename(f):20s}  ({size_kb:7.1f} KB)\")\n",
    "\n",
    "if len(data_files) == 0:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No files found matching {file_pattern}. \"\n",
    "        \"If needed, change the working directory or file_pattern.\"\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Build the combined DataFrame for Station 41025\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "df_41025 = build_station_df(\"41025h\")\n",
    "\n",
    "print(\"\\nCombined Station 41025 DataFrame:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Index range:\", df_41025.index.min(), \"→\", df_41025.index.max())\n",
    "print(\"Total rows:\", len(df_41025))\n",
    "print(\"Columns:\", df_41025.columns.tolist())\n",
    "\n",
    "# Show a quick preview\n",
    "display(df_41025.head())\n",
    "display(df_41025.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95e8dddd-c52f-4a6f-b63a-69b859110717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime index summary\n",
      "----------------------------------------\n",
      "Start: 2013-12-31 23:50:00\n",
      "End  : 2019-12-31 23:50:00\n",
      "Rows : 117882\n",
      "\n",
      "Time step statistics (hours):\n",
      "count    117881.000000\n",
      "mean          0.446077\n",
      "std          12.281906\n",
      "min           0.166667\n",
      "25%           0.166667\n",
      "50%           0.166667\n",
      "75%           1.000000\n",
      "max        3881.166667\n",
      "Name: datetime, dtype: float64\n",
      "\n",
      "Core variables present: ['WVHT', 'DPD', 'APD', 'WSPD', 'GST']\n",
      "\n",
      "% missing per core variable:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WVHT</th>\n",
       "      <th>DPD</th>\n",
       "      <th>APD</th>\n",
       "      <th>WSPD</th>\n",
       "      <th>GST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missing_%</th>\n",
       "      <td>62.441255</td>\n",
       "      <td>62.441255</td>\n",
       "      <td>62.441255</td>\n",
       "      <td>0.92126</td>\n",
       "      <td>0.923805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                WVHT        DPD        APD     WSPD       GST\n",
       "missing_%  62.441255  62.441255  62.441255  0.92126  0.923805"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# QUICK SANITY CHECKS ON STATION 41025 DATA\n",
    "# ============================================================================\n",
    "print(\"Datetime index summary\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Start:\", df_41025.index.min())\n",
    "print(\"End  :\", df_41025.index.max())\n",
    "print(\"Rows :\", len(df_41025))\n",
    "\n",
    "# Check spacing between timestamps (should be mostly 1 hour)\n",
    "dt_diff = df_41025.index.to_series().diff().dropna()\n",
    "dt_hours = dt_diff.dt.total_seconds() / 3600\n",
    "\n",
    "print(\"\\nTime step statistics (hours):\")\n",
    "print(dt_hours.describe())\n",
    "\n",
    "# Core variables we care about\n",
    "core_vars = [v for v in [\"WVHT\", \"DPD\", \"APD\", \"WSPD\", \"GST\"] if v in df_41025.columns]\n",
    "print(\"\\nCore variables present:\", core_vars)\n",
    "\n",
    "missing_summary = (\n",
    "    df_41025[core_vars]\n",
    "    .isna()\n",
    "    .mean()\n",
    "    .mul(100)\n",
    "    .rename(\"missing_%\")\n",
    "    .to_frame()\n",
    ")\n",
    "\n",
    "print(\"\\n% missing per core variable:\")\n",
    "display(missing_summary.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8c371-da21-4458-b6b0-e31909919e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
